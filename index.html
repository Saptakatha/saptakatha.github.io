<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Saptakatha Adak</title>
  
  <meta name="author" content="Saptakatha Adak">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
	
  <style>
/* 		body {
			font-family: "Lato", sans-serif;
		} */

		.sidenav {
			width: 130px;
			position: fixed;
			z-index: 1;
			top: 55px;
			left: 300px;
/* 			background: #eee; */
			overflow-x: hidden;
			padding: 8px 0;
		}

		.sidenav a {
			padding: 6px 8px 6px 16px;
			text-decoration: none;
/* 			font-size: 25px; */
/* 			color: #2196F3; */
			display: block;
		}

/* 		.sidenav a:hover {
			color: #064579;
		} */

		.main {
			margin-left: 140px; /* Same width as the sidebar + left position in px */
			font-size: 28px; /* Increased text to enable scrolling */
			padding: 0px 10px;
		}

		@media screen and (max-height: 450px) {
			.sidenav {padding-top: 15px;}
			.sidenav a {font-size: 18px;}
		}
	</style>
	
</head>

<body>
  <div class="sidenav">
    <a href="https://saptakatha.github.io"><img src="images/Saptakatha_github_avatar_round_28.png" width="28"></a>
    <a href="https://saptakatha.github.io">About</a>
    <a href="#research">Research</a>
    <a href="#awards">Awards</a>
    <a href="#service">Service</a>
    <!-- <a href="#education">Education</a> -->
  </div>
	
  <div class="main">
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Saptakatha Adak</name>
              </p>
		    <p>I am a Research Engineer at <a href="https://www.philips.co.in/">Philips India</a>, where I work on Medical Imaging based AI problems on CT and MRI modalities. Previously, I worked as a Research Scientist at <a href="https://buddi.ai/">BUDDI.AI</a>, where my work was focussed on computer vision and natural language processing based problems in the healthcare domain.
              </p>
	      <p>
	        Prior to that, I did my masters in Computer Science and Engineering from <a href="https://www.iitm.ac.in/">IIT Madras</a>, during which I worked as an MS research scholar in <a href="http://www.cse.iitm.ac.in/~vplab/">Visualization and Perception Lab</a> on video object segmentation (<a href="https://drive.google.com/file/d/1QggXiG-q7741lyKdsT43aWHzc-iO9PqX/view?usp=sharing">thesis</a>) and scene segmentation in adverse scenarios. I was advised by <a href="http://www.cse.iitm.ac.in/~sdas/">Prof. Sukhendu Das</a>.
	      </p>
              
              <p style="text-align:center">
                <a href="mailto:saptakatha2@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/CV_Saptakatha_Adak.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=zpUk0NcAAAAJ">Google Scholar</a> &nbsp/&nbsp
		<a href="http://www.linkedin.com/in/saptakatha-adak/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/SaptakathaAdak_280x280.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/SaptakathaAdak_280x280_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
	      <a name="research"></a><br>
              <heading>Research</heading>
              <!-- <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Papers included in the MS thesis are <span class="highlight">highlighted</span>.
              </p> -->
	      <p>Papers included in the MS thesis are <span class="highlight">highlighted</span>.</p>    
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="iconip_stop()" onmouseover="iconip_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='iconip_image'>
		<img src="images/iconip_multi_obj_seg_160.gif">
		<!-- <video  width=100% height=100% muted autoplay loop>
                <source src="images/iconip_multi_obj_seg_160.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video> -->
		</div>
                <img src='images/iconip_multi_obj_seg_160.png' width="160">
              </div>
              <script type="text/javascript">
                function iconip_start() {
                  document.getElementById('iconip_image').style.opacity = "1";
                }

                function iconip_stop() {
                  document.getElementById('iconip_image').style.opacity = "0";
                }
                iconip_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/iconip19-pixelgcn-vos/">
                <papertitle>Motion-based Occlusion-aware Pixel Graph Network for Video Object Segmentation</papertitle>
              </a>
              <br>
              <strong>Saptakatha Adak</strong>,
              <a href="http://www.cse.iitm.ac.in/~sdas/">Sukhendu Das</a>
              <br>
							<em>International Conference on Neural Information Processing (ICONIP)</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
			  <strong><a href="data/ICONIP-2019_best_student_paper_award.pdf" style="color: blue">[Best Student Paper]<a/></strong>
			  <br>
              <a href="https://sites.google.com/view/iconip19-pixelgcn-vos/">project page</a>
              /
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-36711-4_43">paper</a>
	      /
	      <a href="data/SaptaICONIP2019.bib">bibtex</a>
              <p></p>
              <p>Introduced a directional attention based pixel graph convolutional network (GCN) with aggregation functions dedicated for segmenting multiple objects of interest in videos having varied motion patterns and undergoing occlusion.</p>
            </td>
          </tr> 

          <tr onmouseout="icipnight_stop()" onmouseover="icipnight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='icipnight_image'>
                <img src="images/night_pred_seg_160.png" width="160">                
                </div>
                <img src='images/night_image_160.png' width="160">
              </div>
              <script type="text/javascript">
                function icipnight_start() {
                  document.getElementById('icipnight_image').style.opacity = "1";
                }

                function icipnight_stop() {
                  document.getElementById('icipnight_image').style.opacity = "0";
                }
                icipnight_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8803299">
              <papertitle>Whatâ€™s there in the dark</papertitle>
              </a>
              <br>
              <a href="https://sauradip.github.io/">Sauradip Nag</a>,
              <strong>Saptakatha Adak</strong>,
              <a href="http://www.cse.iitm.ac.in/~sdas/">Sukhendu Das</a>
              <br>
							<em>International Conference in Image Processing (ICIP)</em>, 2019 &nbsp <font color="red"><strong>(Spotlight Paper)</strong></font>
              <br>
	      <strong><a href="https://www.2019.ieeeicip.org/2019.ieeeicip.org/indexfade.html?action=page3&id=9" style="color: blue">[Among Top 10% papers]</a></strong>
	      <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/8803299">paper</a>
              /
              <a href="https://github.com/sauradip/night_image_semantic_segmentation">code</a>
	      /
	      <a href="data/SaptaICIP2019.bib">bibtex</a>
              <p></p>
              <p>A dual-channel network for segmenting objects in night-time traffic scenes to facilitate the autonomous systems.</p>
            </td>

          <tr onmouseout="visapp_stop()" onmouseover="visapp_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='visapp_image'>
                <img src="images/visapp_seg_160.gif">
		</div>
                <img src='images/visapp_seg_0_160.gif' width="160">
              </div>
              <script type="text/javascript">
                function visapp_start() {
                  document.getElementById('visapp_image').style.opacity = "1";
                }
                function visapp_stop() {
                  document.getElementById('visapp_image').style.opacity = "0";
                }
                visapp_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/visapp19-tempseggan-vos/">
                <papertitle>TempSeg-GAN: Segmenting Objects in Videos Adversarially using Temporal Information</papertitle>
              </a>
              <br>
              
              <strong>Saptakatha Adak</strong>,
              <a href="http://www.cse.iitm.ac.in/~sdas/">Sukhendu Das</a>
              <br>
							<em>International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP part of VISIGRAPP)</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
	      <font color="blue"><strong>[Best Student Paper Award Finalist]</strong></font>
	      <br>
              <a href="https://sites.google.com/view/visapp19-tempseggan-vos/">project page</a> /
              <a href="https://www.scitepress.org/Link.aspx?doi=10.5220/0007254302210232">paper</a> /
	      <a href="data/SaptaVISAPP2019.bib">bibtex</a>
              <p></p>
              <p>Incorporated optical flow based temporal information in formulation of objective functions to improve consistency among distant frames over time.
              </p>
            </td>
          </tr> 


          <tr onmouseout="icvgip_stop()" onmouseover="icvgip_start()"   bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='icvgip_image'>
                  <img src='images/icvgip_seg_160.gif' width="160"></div>
                <img src='images/icvgip_seg_0_160.gif' width="160">
              </div>
              <script type="text/javascript">
                function icvgip_start() {
                  document.getElementById('icvgip_image').style.opacity = "1";
                }

                function icvgip_stop() {
                  document.getElementById('icvgip_image').style.opacity = "0";
                }
                icvgip_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/icvgip18-vidseggan-vos/">
                <papertitle>VidSeg-GAN: Generative Adversarial Network for Video Object Segmentation Tasks</papertitle>
              </a>
              <br>
              <strong>Saptakatha Adak</strong>,
              <a href="http://www.cse.iitm.ac.in/~sdas/">Sukhendu Das</a>
              <br>
							<em> Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP)</em>, 2018
			  <br>
			  <font color="red"><strong>(Short Oral Presentation)</strong></font>
              <br>
	      <a href="https://sites.google.com/view/icvgip18-vidseggan-vos/">project page</a> /
              <a href="https://dl.acm.org/doi/10.1145/3293353.3293381">paper</a> /
	      <a href="data/SaptaICVGIP2018.bib">bibtex</a>
              <p></p>
              <p>
                An adversarial training based network designed to generate segmentation masks of objects of interest in videos.
              </p>
            </td>
          </tr> 


          <tr onmouseout="cvip_stop()" onmouseover="cvip_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cvip_image'>
                <img src="images/cvip_PO_dataset_160.jpg">
                </div>
                <img src='images/cvip_PO_dataset_160.jpg' width="160">
              </div>
              <script type="text/javascript">
                function cvip_start() {
                  document.getElementById('cvip_image').style.opacity = "1";
                }

                function cvip_stop() {
                  document.getElementById('cvip_image').style.opacity = "0";
                }
                cvip_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-981-32-9088-4_36">
                <papertitle>Things at your desk: A Portable Object Dataset</papertitle>
              </a>
              <br>

              <strong>Saptakatha Adak</strong>
              <br>
							<em>International Conference on Computer Vision and Image Processing (CVIP)</em>, 2018
              <br>
	      <font color="red"><strong>(Oral Presentation)</strong></font> &nbsp <strong><a href="data/CVIP-2018_best_student_paper_award.pdf" style="color: blue">[IAPR Best Student Paper]</a></strong>
	      <br>
              <a href="https://link.springer.com/chapter/10.1007/978-981-32-9088-4_36">paper</a> /
	      <a href="data/SaptaCVIP2018.bib">bibtex</a>
              <p></p>
              <p>
              A novel dataset consisting of portable objects captured in unconstrained environments with varying illumination condition, background clutter, occlusion, camera shake and diverse object characteristics like in-plane rotation, appearance variation, etc.
              </p>
            </td>
          </tr>

          

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Awards</heading><a name="awards"></a>
            </td>
          </tr>
        </tbody></table>
	<table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>            
            <td valign="center">
              Best Student Paper Award in ICONIP, 2019
	      <br>
	      <br>
	      IAPR Best Student Paper Award in CVIP, 2018
	      <br>
	      <br>
	      Best Student Project Award for Undergraduate project by TCS, India in 2017
            </td>
          </tr>          
        </tbody></table>
	      
	      
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading><a name="service"></a>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/iconip_logo_160.png"></td>
            <td width="75%" valign="center">
              Reviewer, ICONIP 2021              
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iitm_logo_160.png" alt="cs188">
            </td>
            <td width="75%" valign="center">
	      Teaching Assistant, Computer Vision (CS6350) Jan-May 2019
              <!-- <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a> -->
              <br>
              <br>
	      Teaching Assistant, Linear Algebra and Random Processes (CS6015) Jul-Nov 2018
              <!-- <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a> -->
              <br>
              <br>
	      Teaching Assistant, Computational Engineering (CS1100) Jul-Nov 2016
              <!-- <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a> -->
	      <br>
              <br>
	      Part of organizing team, TCS Research Interaction Day 2016
	      <br>
              <br>
	      Part of ground-truth creation team, Mouse Brain Architecture Project jointly carried out under the Cold Springs Harbor Laboratory (CSHL), USA and Indian Institute of Technology Madras (IITM) Jan 2017 - Jul 2018
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a href="https://github.com/jonbarron/jonbarron_website" style="font-size:small">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
	</div>
</body>

</html>
